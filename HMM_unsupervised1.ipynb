{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from matplotlib import animation\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import string\n",
    "\n",
    "####################\n",
    "# WORDCLOUD FUNCTIONS\n",
    "####################\n",
    "def mask():\n",
    "    # Parameters.\n",
    "    r = 128\n",
    "    d = 2 * r + 1\n",
    "\n",
    "    # Get points in a circle.\n",
    "    y, x = np.ogrid[-r:d-r, -r:d-r]\n",
    "    circle = (x**2 + y**2 <= r**2)\n",
    "\n",
    "    # Create mask.\n",
    "    mask = 255 * np.ones((d, d), dtype=np.uint8)\n",
    "    mask[circle] = 0\n",
    "\n",
    "    return mask\n",
    "\n",
    "def text_to_wordcloud(text, max_words=50, title='', show=True):\n",
    "    plt.close('all')\n",
    "\n",
    "    # Generate a wordcloud image.\n",
    "    wordcloud = WordCloud(random_state=0,\n",
    "                          max_words=max_words,\n",
    "                          background_color='white',\n",
    "                          mask=mask()).generate(text)\n",
    "\n",
    "    # Show the image.\n",
    "    if show:\n",
    "        plt.imshow(wordcloud, interpolation='bilinear')\n",
    "        plt.axis('off')\n",
    "        plt.title(title, fontsize=24)\n",
    "        plt.show()\n",
    "\n",
    "    return wordcloud\n",
    "\n",
    "def states_to_wordclouds(hmm, obs_map, max_words=50, show=True):\n",
    "    # Initialize.\n",
    "    M = 100000\n",
    "    n_states = len(hmm.A)\n",
    "    obs_map_r = obs_map_reverser(obs_map)\n",
    "    wordclouds = []\n",
    "\n",
    "    # Generate a large emission.\n",
    "    emission, states = hmm.generate_emission(M)\n",
    "\n",
    "    # For each state, get a list of observations that have been emitted\n",
    "    # from that state.\n",
    "    obs_count = []\n",
    "    for i in range(n_states):\n",
    "        obs_lst = np.array(emission)[np.where(np.array(states) == i)[0]]\n",
    "        obs_count.append(obs_lst)\n",
    "\n",
    "    # For each state, convert it into a wordcloud.\n",
    "    for i in range(n_states):\n",
    "        obs_lst = obs_count[i]\n",
    "        sentence = [obs_map_r[j] for j in obs_lst]\n",
    "        sentence_str = ' '.join(sentence)\n",
    "\n",
    "        wordclouds.append(text_to_wordcloud(sentence_str, max_words=max_words, title='State %d' % i, show=show))\n",
    "\n",
    "    return wordclouds\n",
    "\n",
    "\n",
    "####################\n",
    "# HMM FUNCTIONS\n",
    "####################\n",
    "\n",
    "def load_sylls(filename):\n",
    "    '''Loads the words and their syllables in a dictionary.\n",
    "       Returns the dictonary with format: word : [#syllables].'''\n",
    "    \n",
    "    syll_dict = {}\n",
    "    \n",
    "    file = open(filename, \"r\")\n",
    "    for line in file:\n",
    "        w = line.split()\n",
    "        #get the word itself as a string\n",
    "        word = w[0]\n",
    "        num_sylls = w[1:]\n",
    "                 \n",
    "            \n",
    "        #map list of syllables to string\n",
    "        #num_sylls = [int(x) for x in num_sylls]\n",
    "        \n",
    "        #add to dictionary\n",
    "        syll_dict[word] = num_sylls\n",
    "\n",
    "    return syll_dict\n",
    "    \n",
    "    file.close()\n",
    "\n",
    "def parse_observations(text):\n",
    "    # Convert text to dataset.\n",
    "    lines = [line.split() for line in text.split('\\n') if line.split()]\n",
    "\n",
    "    obs_counter = 0\n",
    "    obs = []\n",
    "    obs_map = {}\n",
    "\n",
    "    for line in lines:\n",
    "        if len(line) != 1:\n",
    "        \n",
    "            obs_elem = []\n",
    "\n",
    "            for word in line:\n",
    "                word = word.strip(\",.()!:-?;'\").lower()\n",
    "                if word not in obs_map and word.isdigit() == False:\n",
    "                    # Add unique words to the observations map.\n",
    "                    obs_map[word] = obs_counter\n",
    "                    obs_counter += 1\n",
    "\n",
    "                # Add the encoded word.\n",
    "                obs_elem.append(obs_map[word])\n",
    "\n",
    "            # Add the encoded sequence.\n",
    "            obs.append(obs_elem)\n",
    "\n",
    "    return obs, obs_map\n",
    "\n",
    "def obs_map_reverser(obs_map):\n",
    "    obs_map_r = {}\n",
    "\n",
    "    for key in obs_map:\n",
    "        obs_map_r[obs_map[key]] = key\n",
    "        \n",
    "    obs_map_r[-1] = \",\\n\"\n",
    "    obs_map_r[-2] = \".\"\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    return obs_map_r\n",
    "\n",
    "def sample_sentence(hmm, obs_map, n_words=100):\n",
    "    # Get reverse map.\n",
    "    obs_map_r = obs_map_reverser(obs_map)\n",
    "    # Sample and convert sentence.  \n",
    "    print('')\n",
    "     \n",
    "    for i in range(3):\n",
    "        emission, states = hmm.generate_emission(40)\n",
    "        stanza = [obs_map_r[j] for j in emission]\n",
    "        #lines = stanza.split(\",\")\n",
    "        stanza = ' '. join(stanza).capitalize()\n",
    "        print(stanza, \".\")\n",
    "    \n",
    "    emission, states = hmm.generate_emission(20)\n",
    "    stanza = [obs_map_r[j] for j in emission]\n",
    "    #lines = stanza.split(\",\")\n",
    "    stanza = ' '. join(stanza).capitalize()\n",
    "    print(stanza, \".\")\n",
    "    \n",
    "\n",
    "\n",
    "####################\n",
    "# HMM VISUALIZATION FUNCTIONS\n",
    "####################\n",
    "\n",
    "def visualize_sparsities(hmm, O_max_cols=50, O_vmax=0.1):\n",
    "    plt.close('all')\n",
    "    plt.set_cmap('viridis')\n",
    "\n",
    "    # Visualize sparsity of A.\n",
    "    plt.imshow(hmm.A, vmax=1.0)\n",
    "    plt.colorbar()\n",
    "    plt.title('Sparsity of A matrix')\n",
    "    plt.show()\n",
    "\n",
    "    # Visualize parsity of O.\n",
    "    plt.imshow(np.array(hmm.O)[:, :O_max_cols], vmax=O_vmax, aspect='auto')\n",
    "    plt.colorbar()\n",
    "    plt.title('Sparsity of O matrix')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "####################\n",
    "# HMM ANIMATION FUNCTIONS\n",
    "####################\n",
    "\n",
    "def animate_emission(hmm, obs_map, M=8, height=12, width=12, delay=1):\n",
    "    # Parameters.\n",
    "    lim = 1200\n",
    "    text_x_offset = 40\n",
    "    text_y_offset = 80\n",
    "    x_offset = 580\n",
    "    y_offset = 520\n",
    "    R = 420\n",
    "    r = 100\n",
    "    arrow_size = 20\n",
    "    arrow_p1 = 0.03\n",
    "    arrow_p2 = 0.02\n",
    "    arrow_p3 = 0.06\n",
    "    \n",
    "    # Initialize.\n",
    "    n_states = len(hmm.A)\n",
    "    obs_map_r = obs_map_reverser(obs_map)\n",
    "    wordclouds = states_to_wordclouds(hmm, obs_map, max_words=20, show=False)\n",
    "\n",
    "    # Initialize plot.    \n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_figheight(height)\n",
    "    fig.set_figwidth(width)\n",
    "    ax.grid('off')\n",
    "    plt.axis('off')\n",
    "    ax.set_xlim([0, lim])\n",
    "    ax.set_ylim([0, lim])\n",
    "\n",
    "    # Plot each wordcloud.\n",
    "    for i, wordcloud in enumerate(wordclouds):\n",
    "        x = x_offset + int(R * np.cos(np.pi * 2 * i / n_states))\n",
    "        y = y_offset + int(R * np.sin(np.pi * 2 * i / n_states))\n",
    "        ax.imshow(wordcloud.to_array(), extent=(x - r, x + r, y - r, y + r), aspect='auto', zorder=-1)\n",
    "\n",
    "    # Initialize text.\n",
    "    text = ax.text(text_x_offset, lim - text_y_offset, '', fontsize=24)\n",
    "        \n",
    "    # Make the arrows.\n",
    "    zorder_mult = n_states ** 2 * 100\n",
    "    arrows = []\n",
    "    for i in range(n_states):\n",
    "        row = []\n",
    "        for j in range(n_states):\n",
    "            # Arrow coordinates.\n",
    "            x_i = x_offset + R * np.cos(np.pi * 2 * i / n_states)\n",
    "            y_i = y_offset + R * np.sin(np.pi * 2 * i / n_states)\n",
    "            x_j = x_offset + R * np.cos(np.pi * 2 * j / n_states)\n",
    "            y_j = y_offset + R * np.sin(np.pi * 2 * j / n_states)\n",
    "            \n",
    "            dx = x_j - x_i\n",
    "            dy = y_j - y_i\n",
    "            d = np.sqrt(dx**2 + dy**2)\n",
    "\n",
    "            if i != j:\n",
    "                arrow = ax.arrow(x_i + (r/d + arrow_p1) * dx + arrow_p2 * dy,\n",
    "                                 y_i + (r/d + arrow_p1) * dy + arrow_p2 * dx,\n",
    "                                 (1 - 2 * r/d - arrow_p3) * dx,\n",
    "                                 (1 - 2 * r/d - arrow_p3) * dy,\n",
    "                                 color=(1 - hmm.A[i][j], ) * 3,\n",
    "                                 head_width=arrow_size, head_length=arrow_size,\n",
    "                                 zorder=int(hmm.A[i][j] * zorder_mult))\n",
    "            else:\n",
    "                arrow = ax.arrow(x_i, y_i, 0, 0,\n",
    "                                 color=(1 - hmm.A[i][j], ) * 3,\n",
    "                                 head_width=arrow_size, head_length=arrow_size,\n",
    "                                 zorder=int(hmm.A[i][j] * zorder_mult))\n",
    "\n",
    "            row.append(arrow)\n",
    "        arrows.append(row)\n",
    "\n",
    "    emission, states = hmm.generate_emission(M)\n",
    "\n",
    "    def animate(i):\n",
    "        if i >= delay:\n",
    "            i -= delay\n",
    "\n",
    "            if i == 0:\n",
    "                arrows[states[0]][states[0]].set_color('red')\n",
    "            elif i == 1:\n",
    "                arrows[states[0]][states[0]].set_color((1 - hmm.A[states[0]][states[0]], ) * 3)\n",
    "                arrows[states[i - 1]][states[i]].set_color('red')\n",
    "            else:\n",
    "                arrows[states[i - 2]][states[i - 1]].set_color((1 - hmm.A[states[i - 2]][states[i - 1]], ) * 3)\n",
    "                arrows[states[i - 1]][states[i]].set_color('red')\n",
    "\n",
    "            # Set text.\n",
    "            text.set_text(' '.join([obs_map_r[e] for e in emission][:i+1]).capitalize())\n",
    "\n",
    "            return arrows + [text]\n",
    "\n",
    "    # Animate!\n",
    "    print('\\nAnimating...')\n",
    "    anim = FuncAnimation(fig, animate, frames=M+delay, interval=1000)\n",
    "\n",
    "    return anim\n",
    "\n",
    "    # honestly this function is so jank but who even fuckin cares\n",
    "    # i don't even remember how or why i wrote this mess\n",
    "    # no one's gonna read this\n",
    "    # hey if you see this tho hmu on fb let's be friends\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import operator\n",
    "import numpy as np\n",
    "\n",
    "class HiddenMarkovModel:\n",
    "    '''\n",
    "    Class implementation of Hidden Markov Models.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, A, O):\n",
    "        '''\n",
    "        Initializes an HMM. Assumes the following:\n",
    "            - States and observations are integers starting from 0. \n",
    "            - There is a start state (see notes on A_start below). There\n",
    "              is no integer associated with the start state, only\n",
    "              probabilities in the vector A_start.\n",
    "            - There is no end state.\n",
    "\n",
    "        Arguments:\n",
    "            A:          Transition matrix with dimensions L x L.\n",
    "                        The (i, j)^th element is the probability of\n",
    "                        transitioning from state i to state j. Note that\n",
    "                        this does not include the starting probabilities.\n",
    "\n",
    "            O:          Observation matrix with dimensions L x D.\n",
    "                        The (i, j)^th element is the probability of\n",
    "                        emitting observation j given state i.\n",
    "\n",
    "        Parameters:\n",
    "            L:          Number of states.\n",
    "            \n",
    "            D:          Number of observations.\n",
    "            \n",
    "            A:          The transition matrix.\n",
    "            \n",
    "            O:          The observation matrix.\n",
    "            \n",
    "            A_start:    Starting transition probabilities. The i^th element\n",
    "                        is the probability of transitioning from the start\n",
    "                        state to state i. For simplicity, we assume that\n",
    "                        this distribution is uniform.\n",
    "        '''\n",
    "\n",
    "        self.L = len(A)\n",
    "        self.D = len(O[0])\n",
    "        self.A = A\n",
    "        self.O = O\n",
    "        self.A_start = [1. / self.L for _ in range(self.L)]\n",
    "\n",
    "\n",
    "    def viterbi(self, x):\n",
    "        '''\n",
    "        Uses the Viterbi algorithm to find the max probability state \n",
    "        sequence corresponding to a given input sequence.\n",
    "\n",
    "        Arguments:\n",
    "            x:          Input sequence in the form of a list of length M,\n",
    "                        consisting of integers ranging from 0 to D - 1.\n",
    "\n",
    "        Returns:\n",
    "            max_seq:    State sequence corresponding to x with the highest\n",
    "                        probability.\n",
    "        '''\n",
    "        print(\"reached\")\n",
    "        M = len(x)      # Length of sequence.\n",
    "\n",
    "        # The (i, j)^th elements of probs and seqs are the max probability\n",
    "        # of the prefix of length i ending in state j and the prefix\n",
    "        # that gives this probability, respectively.\n",
    "        #\n",
    "        # For instance, probs[1][0] is the probability of the prefix of\n",
    "        # length 1 ending in state 0.\n",
    "        probs = [[0. for _ in range(self.L)] for _ in range(M + 1)]\n",
    "        seqs = [['' for _ in range(self.L)] for _ in range(M + 1)]\n",
    "        \n",
    "        # initialize the first row\n",
    "        for i in range(self.L):\n",
    "            probs[1][i] = self.A_start[i] * self.O[i][x[0]]\n",
    "            seqs[1][i] = \"\" + str(i)\n",
    "        for i in range(1, M): \n",
    "            for j in range(0, self.L): \n",
    "                max_ind = 0\n",
    "                # initial probability \n",
    "                max_prob = probs[i][0] * self.A[0][j] * self.O[j][x[i]]\n",
    "                # iterates through all the states and finds the max prob\n",
    "                for t in range(1, self.L): \n",
    "                    prob = probs[i][t] * self.A[t][j] * self.O[j][x[i]]\n",
    "                    if max_prob < prob: \n",
    "                        max_ind = t\n",
    "                        max_prob = prob\n",
    "                # sets prob array at this state and row to max prob\n",
    "                probs[i+1][j] = max_prob\n",
    "                # updates seqs\n",
    "                seqs[i+1][j] = seqs[i][max_ind] + str(j)\n",
    "        # finds the maximum prob and index at the Mth row \n",
    "        maxind, maxprob = max(enumerate(probs[M]), key =operator.itemgetter(1))\n",
    "        # adds seq\n",
    "        max_seq = '' + seqs[len(probs)-1][maxind] + str(maxind)\n",
    "        return max_seq\n",
    "\n",
    "    def forward(self, x, normalize=False):\n",
    "        '''\n",
    "        Uses the forward algorithm to calculate the alpha probability\n",
    "        vectors corresponding to a given input sequence.\n",
    "\n",
    "        Arguments:\n",
    "            x:          Input sequence in the form of a list of length M,\n",
    "                        consisting of integers ranging from 0 to D - 1.\n",
    "\n",
    "            normalize:  Whether to normalize each set of alpha_j(i) vectors\n",
    "                        at each i. This is useful to avoid underflow in\n",
    "                        unsupervised learning.\n",
    "\n",
    "        Returns:\n",
    "            alphas:     Vector of alphas.\n",
    "\n",
    "                        The (i, j)^th element of alphas is alpha_j(i),\n",
    "                        i.e. the probability of observing prefix x^1:i\n",
    "                        and state y^i = j.\n",
    "\n",
    "                        e.g. alphas[1][0] corresponds to the probability\n",
    "                        of observing x^1:1, i.e. the first observation,\n",
    "                        given that y^1 = 0, i.e. the first state is 0.\n",
    "        '''\n",
    "\n",
    "        # if normalize is True \n",
    "        if (normalize): \n",
    "            M = len(x)      # Length of sequence.\n",
    "            alphas = [[0. for _ in range(self.L)] for _ in range(M + 1)]\n",
    "            # initialize first state \n",
    "            for i in range(self.L):\n",
    "                alphas[1][i] = self.A_start[i] * self.O[i][x[0]]\n",
    "            # for each row \n",
    "            for r in range(1, M): \n",
    "                # for each column \n",
    "                for c in range(self.L): \n",
    "                    # create an array that contains the sum for each column \n",
    "                    sum_arr = []\n",
    "                    # compute sum for each column \n",
    "                    for t in range(self.L): \n",
    "                        sum_arr.append(alphas[r][t] * self.A[t][c] * self.O[c][x[r]])\n",
    "                    # make the value at this specific state and row equal to the sum of the sum_arr\n",
    "                    alphas[r+1][c] = sum(sum_arr)\n",
    "                # compute normalization constant \n",
    "                # equal to the sum of each row in alpha \n",
    "                normalize_const = sum(alphas[r+1])\n",
    "                # divide each value in the current row by this constant \n",
    "                for j in range(self.L): \n",
    "                    alphas[r+1][j] /= normalize_const\n",
    "            return alphas \n",
    "        # if normalize is False \n",
    "        else: \n",
    "            M = len(x)      # Length of sequence.\n",
    "            alphas = [[0. for _ in range(self.L)] for _ in range(M + 1)]\n",
    "            #initilize the first state\n",
    "            for i in range(self.L):\n",
    "                alphas[1][i] = self.O[i][x[0]] * self.A_start[i]\n",
    "            # for each ro w\n",
    "            for r in range(1, M): \n",
    "                # for each column \n",
    "                for c in range(self.L): \n",
    "                    # create an array that contains the sum for each column \n",
    "                    sum_arr = []\n",
    "                    # compute the sum for each column \n",
    "                    for t in range(self.L): \n",
    "                        sum_arr.append(alphas[r][t] * self.A[t][c] * self.O[c][x[r]])\n",
    "                    # make the value at this specific state and row equal to the sum of the sum_arr\n",
    "                    alphas[r+1][c] = sum(sum_arr)\n",
    "        return alphas\n",
    "\n",
    "\n",
    "    def backward(self, x, normalize=False):\n",
    "        '''\n",
    "        Uses the backward algorithm to calculate the beta probability\n",
    "        vectors corresponding to a given input sequence.\n",
    "\n",
    "        Arguments:\n",
    "            x:          Input sequence in the form of a list of length M,\n",
    "                        consisting of integers ranging from 0 to D - 1.\n",
    "\n",
    "            normalize:  Whether to normalize each set of alpha_j(i) vectors\n",
    "                        at each i. This is useful to avoid underflow in\n",
    "                        unsupervised learning.\n",
    "\n",
    "        Returns:\n",
    "            betas:      Vector of betas.\n",
    "\n",
    "                        The (i, j)^th element of betas is beta_j(i), i.e.\n",
    "                        the probability of observing prefix x^(i+1):M and\n",
    "                        state y^i = j.\n",
    "\n",
    "                        e.g. betas[M][0] corresponds to the probability\n",
    "                        of observing x^M+1:M, i.e. no observations,\n",
    "                        given that y^M = 0, i.e. the last state is 0.\n",
    "        '''\n",
    "\n",
    "        M = len(x)      # Length of sequence.\n",
    "        betas = [[0. for _ in range(self.L)] for _ in range(M + 1)]\n",
    "        if (normalize): \n",
    "            # initialize first state \n",
    "            for i in range(self.L):\n",
    "                betas[M][i] = 1\n",
    "            # for each row \n",
    "            for r in range(M, 1, -1): \n",
    "                # for each column \n",
    "                for c in range(self.L): \n",
    "                    # compute sum for each column \n",
    "                    for t in range(self.L): \n",
    "                        betas[r-1][c] += betas[r][t] * self.A[c][t]*self.O[t][x[r-1]]\n",
    "                # compute normalization constant \n",
    "                # equal to the sum of each row in alpha \n",
    "                normalize_const = sum(betas[r-1])\n",
    "                # divide each value in the current row by this constant \n",
    "                for j in range(self.L): \n",
    "                    betas[r-1][j] /= normalize_const\n",
    "            return betas\n",
    "        # if normalize is False \n",
    "        else: \n",
    "            # initialize first state \n",
    "            for i in range(self.L):\n",
    "                betas[M][i] = 1\n",
    "            # for each row \n",
    "            for r in range(M, 1, -1): \n",
    "                # for each column \n",
    "                for c in range(self.L): \n",
    "                    # compute sum for each column \n",
    "                    for t in range(self.L): \n",
    "                        betas[r-1][c] += betas[r][t] * self.A[c][t]*self.O[t][x[r-1]]\n",
    "        return betas\n",
    "\n",
    "    def supervised_learning(self, X, Y):\n",
    "        '''\n",
    "        Trains the HMM using the Maximum Likelihood closed form solutions\n",
    "        for the transition and observation matrices on a labeled\n",
    "        datset (X, Y). Note that this method does not return anything, but\n",
    "        instead updates the attributes of the HMM object.\n",
    "\n",
    "        Arguments:\n",
    "            X:          A dataset consisting of input sequences in the form\n",
    "                        of lists of variable length, consisting of integers \n",
    "                        ranging from 0 to D - 1. In other words, a list of\n",
    "                        lists.\n",
    "\n",
    "            Y:          A dataset consisting of state sequences in the form\n",
    "                        of lists of variable length, consisting of integers \n",
    "                        ranging from 0 to L - 1. In other words, a list of\n",
    "                        lists.\n",
    "\n",
    "                        Note that the elements in X line up with those in Y.\n",
    "        '''\n",
    "\n",
    "        # Calculate each element of A using the M-step formulas.\n",
    "        for a in range(self.L): \n",
    "            for b in range(self.L): \n",
    "                n = 0\n",
    "                d = 0\n",
    "                for i in range(len(X)): \n",
    "                    for j in range(1, len(X[i])): \n",
    "                        if Y[i][j-1] == a: \n",
    "                            d += 1\n",
    "                            if Y[i][j] == b: \n",
    "                                n += 1\n",
    "                self.A[a][b] = n/d \n",
    "\n",
    "        # Calculate each element of O using the M-step formulas.\n",
    "\n",
    "        for w in range(len(self.O)): \n",
    "            for z in range(len(self.O[0])): \n",
    "                n = 0 \n",
    "                d = 0 \n",
    "                for i in range(len(X)): \n",
    "                    for j in range(len(X[i])): \n",
    "                        if Y[i][j] == w: \n",
    "                            d += 1\n",
    "                            if X[i][j] == z: \n",
    "                                n += 1\n",
    "                    self.O[w][z] = n/d\n",
    "\n",
    "\n",
    "    def unsupervised_learning(self, X, N_iters):\n",
    "        '''\n",
    "        Trains the HMM using the Baum-Welch algorithm on an unlabeled\n",
    "        datset X. Note that this method does not return anything, but\n",
    "        instead updates the attributes of the HMM object.\n",
    "\n",
    "        Arguments:\n",
    "            X:          A dataset consisting of input sequences in the form\n",
    "                        of lists of length M, consisting of integers ranging\n",
    "                        from 0 to D - 1. In other words, a list of lists.\n",
    "\n",
    "            N_iters:    The number of iterations to train on.\n",
    "        '''\n",
    "\n",
    "        for epoch in range(N_iters): \n",
    "            O_numerator = np.zeros([self.L, self.D])\n",
    "            O_denominator = np.zeros([self.L, 1])\n",
    "            A_numerator = np.zeros([self.L, self.L])\n",
    "            A_denominator = np.zeros([self.L, 1])\n",
    "\n",
    "            for seq in X: \n",
    "                alphas = self.forward(seq, normalize=True)\n",
    "                betas = self.backward(seq, normalize=True)\n",
    "                M = len(seq)\n",
    "\n",
    "                for j in range(1, M+1): \n",
    "                    gamma = []\n",
    "                    sum_gamma = 0\n",
    "                    for a in range(0, self.L): \n",
    "                        sum_gamma += alphas[j][a] * betas[j][a]\n",
    "                        gamma.append(alphas[j][a] * betas[j][a])\n",
    "                    gamma = np.copy(gamma)\n",
    "                    gamma = np.divide(gamma, sum_gamma)\n",
    "\n",
    "                    for a in range(self.L): \n",
    "                        if j != M: \n",
    "                            A_denominator[a] += gamma[a]\n",
    "                        O_numerator[a][seq[j-1]] += gamma[a]\n",
    "                        O_denominator[a] += gamma[a]\n",
    "\n",
    "                for j in range(1, M): \n",
    "                    arr = np.zeros([self.L, self.L])\n",
    "                    for a in range(self.L): \n",
    "                        for b in range(self.L): \n",
    "                            arr[a][b] += alphas[j][a] * self.O[b][seq[j]] * self.A[a][b] * betas[j+1][b]\n",
    "                    \n",
    "                    sum_normal = 0\n",
    "                    for i in range(self.L):\n",
    "                        for j in range(self.L):  \n",
    "                            sum_normal += arr[i][j]\n",
    "                    for i in range(self.L): \n",
    "                        for j in range(self.L): \n",
    "                            arr[i][j] /= sum_normal\n",
    "                    for a in range(self.L): \n",
    "                        for b in range(self.L): \n",
    "                            A_numerator[a][b] += arr[a][b]\n",
    "\n",
    "            self.A = np.divide(A_numerator, A_denominator)\n",
    "            self.O = np.divide(O_numerator, O_denominator)\n",
    "    def generate_emission(self, n_sylls):\n",
    "        '''\n",
    "        Generates an emission of length M, assuming that the starting state\n",
    "        is chosen uniformly at random. \n",
    "\n",
    "        Arguments:\n",
    "            M:          Length of the emission to generate.\n",
    "\n",
    "        Returns:\n",
    "            emission:   The randomly generated emission as a list.\n",
    "\n",
    "            states:     The randomly generated states as a list.\n",
    "        '''\n",
    "        emission = []\n",
    "        states = []\n",
    "        r = np.random.choice(self.L, 1)\n",
    "        count = 0\n",
    "        sylls = load_sylls(\"data/Syllable_dictionary.txt\")\n",
    "        \n",
    "        #text = open(os.path.join(os.getcwd(), 'data/shakespeare.txt')).read()\n",
    "        obs, obs_map = parse_observations(text)\n",
    "        #obs_map maps the word to its id\n",
    "        \n",
    "        #obs_map_r maps the id to its word\n",
    "        obs_map_r = obs_map_reverser(obs_map)\n",
    "\n",
    "        while count < n_sylls: \n",
    "            \n",
    "            \n",
    "            Y_sum = sum(self.A[r[0]])\n",
    "            X_sum = sum(self.O[r[0]])\n",
    "            Y_prob = np.divide(self.A[r[0]], Y_sum)\n",
    "            X_prob = np.divide(self.O[r[0]], X_sum)\n",
    "            Y_random = np.random.choice(self.L, 1, p = Y_prob)\n",
    "            X_random = np.random.choice(self.D, 1, p = X_prob)\n",
    "            \n",
    "            #print(X_random)\n",
    "            \n",
    "            #now that we have X ( by id) and Y, we need to see the syllable info\n",
    "            word = obs_map_r[X_random[0]]\n",
    "            #print(word)\n",
    "        \n",
    "            if word not in sylls.keys():\n",
    "                #print(word, \" not in sylls\")\n",
    "                sylls[word] = [\"2\", \"1\"]\n",
    "                \n",
    "            \n",
    "            #case where there is only one possible number of syllables for that word\n",
    "            if len(sylls[word]) == 1: \n",
    "                s = int(sylls[word][0])\n",
    "                if count + s > n_sylls:\n",
    "                #find another word because we exceeded 10 syllables \n",
    "                    continue #skips to end of while loop\n",
    "                else:\n",
    "                    count += s \n",
    "            else:\n",
    "                #if the possible syllables are > 1\n",
    "                s1 = sylls[word][0]\n",
    "                s2 = sylls[word][1]\n",
    "                \n",
    "                #tackle the ending cases\n",
    "                \n",
    "                #first value is the E value (s1 is the E option)\n",
    "                \n",
    "                if s1[0] == \"E\":\n",
    "                    \n",
    "                    #if both the options exceed 10 syllables -> get new number\n",
    "                    if count + int(s2) > n_sylls and count + int(s1[1]) > n_sylls:\n",
    "                        continue\n",
    "                    #E option hits 10 syllables -> choose E option\n",
    "                    elif count + int(s1[1]) == n_sylls:\n",
    "                        count += int(s1[1])\n",
    "                    #normal option uder 10 syllables -> choose that option\n",
    "                    elif count + int(s2) <= n_sylls:\n",
    "                        count += int(s2)\n",
    "                    else:\n",
    "                        count += int(s2)\n",
    "\n",
    "                #s2 is the E option\n",
    "                elif s2[0] == \"E\":\n",
    "                    \n",
    "                    #if both the options exceed 10 syllables -> get new number\n",
    "                    if count + int(s1[0]) > n_sylls and count + int(s2[1]) > n_sylls:\n",
    "                        continue\n",
    "                    #E option hits 10 syllables -> choose E option\n",
    "                    elif count + int(s2[1]) == n_sylls:\n",
    "                        count += int(s2[1])\n",
    "                    #normal option hits 10 syllables -> choose that option\n",
    "                    elif count + int(s1) <= n_sylls:\n",
    "                        count += int(s1)\n",
    "                    #otherwise its under 10 syllables -> choose normal option\n",
    "                    else:\n",
    "                        count += int(s1)\n",
    "                        \n",
    "                \n",
    "                #no E option\n",
    "                elif s2[0] != \"E\" and s1[0] != \"E\":\n",
    "                    #both options over 10 syllables\n",
    "                    if int(s1) + count > n_sylls and int(s2) + count > n_sylls:\n",
    "                        continue\n",
    "                    elif int(s2) + count <= n_sylls:\n",
    "                        count += int(s2)\n",
    "                    elif int(s1) + count <= n_sylls:\n",
    "                        count += int(s1)\n",
    "                    else:\n",
    "                        count += int(s1)\n",
    "                \n",
    "                    \n",
    "\n",
    "            emission.append(X_random[0])\n",
    "            states.append(Y_random[0])\n",
    "            r = np.random.choice(self.L, 1)\n",
    "            \n",
    "            #for denoting the commas\n",
    "            if count % 10 == 0 and count != 0 and count != n_sylls:\n",
    "                emission.append(-1)\n",
    "                states.append(-1)\n",
    "            #print(count)\n",
    "            \n",
    "            \n",
    "        return emission, states\n",
    "\n",
    "    def probability_alphas(self, x):\n",
    "        '''\n",
    "        Finds the maximum probability of a given input sequence using\n",
    "        the forward algorithm.\n",
    "\n",
    "        Arguments:\n",
    "            x:          Input sequence in the form of a list of length M,\n",
    "                        consisting of integers ranging from 0 to D - 1.\n",
    "\n",
    "        Returns:\n",
    "            prob:       Total probability that x can occur.\n",
    "        '''\n",
    "\n",
    "        # Calculate alpha vectors.\n",
    "        alphas = self.forward(x)\n",
    "\n",
    "        # alpha_j(M) gives the probability that the state sequence ends\n",
    "        # in j. Summing this value over all possible states j gives the\n",
    "        # total probability of x paired with any state sequence, i.e.\n",
    "        # the probability of x.\n",
    "        prob = sum(alphas[-1])\n",
    "        return prob\n",
    "\n",
    "\n",
    "    def probability_betas(self, x):\n",
    "        '''\n",
    "        Finds the maximum probability of a given input sequence using\n",
    "        the backward algorithm.\n",
    "\n",
    "        Arguments:\n",
    "            x:          Input sequence in the form of a list of length M,\n",
    "                        consisting of integers ranging from 0 to D - 1.\n",
    "\n",
    "        Returns:\n",
    "            prob:       Total probability that x can occur.\n",
    "        '''\n",
    "\n",
    "        betas = self.backward(x)\n",
    "\n",
    "        # beta_j(1) gives the probability that the state sequence starts\n",
    "        # with j. Summing this, multiplied by the starting transition\n",
    "        # probability and the observation probability, over all states\n",
    "        # gives the total probability of x paired with any state\n",
    "        # sequence, i.e. the probability of x.\n",
    "        prob = sum([betas[1][j] * self.A_start[j] * self.O[j][x[0]] \\\n",
    "                    for j in range(self.L)])\n",
    "\n",
    "        return prob\n",
    "\n",
    "\n",
    "def supervised_HMM(X, Y):\n",
    "    '''\n",
    "    Helper function to train a supervised HMM. The function determines the\n",
    "    number of unique states and observations in the given data, initializes\n",
    "    the transition and observation matrices, creates the HMM, and then runs\n",
    "    the training function for supervised learning.\n",
    "\n",
    "    Arguments:\n",
    "        X:          A dataset consisting of input sequences in the form\n",
    "                    of lists of variable length, consisting of integers \n",
    "                    ranging from 0 to D - 1. In other words, a list of lists.\n",
    "\n",
    "        Y:          A dataset consisting of state sequences in the form\n",
    "                    of lists of variable length, consisting of integers \n",
    "                    ranging from 0 to L - 1. In other words, a list of lists.\n",
    "                    Note that the elements in X line up with those in Y.\n",
    "    '''\n",
    "    # Make a set of observations.\n",
    "    observations = set()\n",
    "    for x in X:\n",
    "        observations |= set(x)\n",
    "\n",
    "    # Make a set of states.\n",
    "    states = set()\n",
    "    for y in Y:\n",
    "        states |= set(y)\n",
    "    \n",
    "    # Compute L and D.\n",
    "    L = len(states)\n",
    "    D = len(observations)\n",
    "\n",
    "    # Randomly initialize and normalize matrix A.\n",
    "    A = [[random.random() for i in range(L)] for j in range(L)]\n",
    "\n",
    "    for i in range(len(A)):\n",
    "        norm = sum(A[i])\n",
    "        for j in range(len(A[i])):\n",
    "            A[i][j] /= norm\n",
    "    \n",
    "    # Randomly initialize and normalize matrix O.\n",
    "    O = [[random.random() for i in range(D)] for j in range(L)]\n",
    "\n",
    "    for i in range(len(O)):\n",
    "        norm = sum(O[i])\n",
    "        for j in range(len(O[i])):\n",
    "            O[i][j] /= norm\n",
    "\n",
    "    # Train an HMM with labeled data.\n",
    "    HMM = HiddenMarkovModel(A, O)\n",
    "    HMM.supervised_learning(X, Y)\n",
    "\n",
    "    return HMM\n",
    "\n",
    "def unsupervised_HMM(X, n_states, N_iters):\n",
    "    '''\n",
    "    Helper function to train an unsupervised HMM. The function determines the\n",
    "    number of unique observations in the given data, initializes\n",
    "    the transition and observation matrices, creates the HMM, and then runs\n",
    "    the training function for unsupervised learing.\n",
    "\n",
    "    Arguments:\n",
    "        X:          A dataset consisting of input sequences in the form\n",
    "                    of lists of variable length, consisting of integers \n",
    "                    ranging from 0 to D - 1. In other words, a list of lists.\n",
    "\n",
    "        n_states:   Number of hidden states to use in training.\n",
    "        \n",
    "        N_iters:    The number of iterations to train on.\n",
    "    '''\n",
    "\n",
    "    # Make a set of observations.\n",
    "    observations = set()\n",
    "    for x in X:\n",
    "        observations |= set(x)\n",
    "    \n",
    "    # Compute L and D.\n",
    "    L = n_states\n",
    "    D = len(observations)\n",
    "    random.seed(2019)\n",
    "    # Randomly initialize and normalize matrix A.\n",
    "    A = [[random.random() for i in range(L)] for j in range(L)]\n",
    "\n",
    "    for i in range(len(A)):\n",
    "        norm = sum(A[i])\n",
    "        for j in range(len(A[i])):\n",
    "            A[i][j] /= norm\n",
    "    \n",
    "    # Randomly initialize and normalize matrix O.\n",
    "    O = [[random.random() for i in range(D)] for j in range(L)]\n",
    "\n",
    "    for i in range(len(O)):\n",
    "        norm = sum(O[i])\n",
    "        for j in range(len(O[i])):\n",
    "            O[i][j] /= norm\n",
    "\n",
    "    # Train an HMM with unlabeled data.\n",
    "    HMM = HiddenMarkovModel(A, O)\n",
    "    HMM.unsupervised_learning(X, N_iters)\n",
    "\n",
    "    return HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from IPython.display import HTML\n",
    "\n",
    "text = open(os.path.join(os.getcwd(), 'data/shakespeare.txt')).read()\n",
    "#wordcloud = text_to_wordcloud(text, title='Shakespeare')\n",
    "\n",
    "obs, obs_map = parse_observations(text)\n",
    "hmm8 = unsupervised_HMM(obs, 3, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Poem:\n",
      "====================\n",
      "\n",
      "He false hath part thou lease express time born ,\n",
      " once now on call the the hair my the struck ,\n",
      " thou things proving worst him first with worst i ,\n",
      " feeble from which and an scope so in by .\n",
      "Near heart profane face mine mine night too then ,\n",
      " mother's strange be thy so sweet me doth thy ,\n",
      " action still heavily mightst grew mine thee ,\n",
      " true on reeleth so thou heir with hand as .\n",
      "Shaken time wish that flower in me doth to ,\n",
      " i gently and are better all devil ,\n",
      " before give blind in infant's have blood tract ,\n",
      " stick'st he cross prison for nothing trust o'er .\n",
      "Mayst wilt one book should even change had quill ,\n",
      " feeds forth yet have it sweets worth doth for in .\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print('\\nSample Poem:\\n====================')\n",
    "print(sample_sentence(hmm8, obs_map, n_words=25))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "obs, obs_map = parse_observations(text)\n",
    "obs_map_r = obs_map_reverser(obs_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "obs_map_r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sylls = load_sylls(\"data/Syllable_dictionary.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sylls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
